{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1.1 - Tensor \n",
    "## Basic data structure in PyTorch\n",
    "\n",
    "The purpose of this notebook is to:\n",
    "* understand tensor structure\n",
    "* know how to indexing and operating on tensors\n",
    "* know hot to moving computation on GPU\n",
    "\n",
    "Tensor is multidimensionall array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of required packages\n",
    "\n",
    "Run only if pytorch hasn't been installed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why we need tensors\n",
    "Flow of tensors through deep neural network\n",
    "<img src=\"./figures/data_flow_1.PNG\" alt=\"data_flow_1.PNG\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations\n",
    "<img src=\"./figures/data_flow_2.PNG\" alt=\"data_flow_2.PNG\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple operations\n",
    "<img src=\"./figures/data_flow_3.PNG\" alt=\"data_flow_3.PNG\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, **a tensor is a multidimensional array**, very similar to numpy array, but it can run on GPU.\n",
    "\n",
    "In math and physics the meaning of the term is much wider, it is an algebraic object describing a multilinear relationship between sets of algebraic objects related to a vector space. \n",
    "\n",
    "## Let's start\n",
    "\n",
    "Import PyThorch packet and check version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2+cu102'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.version.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor dimensionality\n",
    "<img src=\"./figures/tensor_dimension.PNG\" alt=\"tensor_dimension.PNG\" width=\"350\">\n",
    "\n",
    "Let's construct a few tensors, get their dimensions and shapes/sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "Dimension is 0, and size is torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "s = torch.tensor(2)\n",
    "print(s)\n",
    "print('Dimension is {}, and size is {}'.format(s.dim(), s.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 0, 1])\n",
      "Dimension is 1, and size is torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([3, 0, 1])\n",
    "print(v)\n",
    "print('Dimension is {}, and size is {}'.format(v.dim(), v.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 2, 0],\n",
      "        [1, 7, 2, 2],\n",
      "        [9, 5, 9, 4]])\n",
      "Dimension is 2, and size is torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "m = torch.tensor([[1, 0, 2, 0], [1, 7, 2, 2], [9, 5, 9, 4]])\n",
    "print(m)\n",
    "print('Dimension is {}, and size is {}'.format(m.dim(), m.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 6., 4., 2.],\n",
      "         [5., 3., 8., 2.],\n",
      "         [7., 3., 1., 1.]],\n",
      "\n",
      "        [[3., 8., 1., 6.],\n",
      "         [3., 6., 4., 7.],\n",
      "         [2., 3., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 2., 0.],\n",
      "         [1., 7., 2., 2.],\n",
      "         [9., 5., 9., 4.]]])\n",
      "Dimension is 3, and size is torch.Size([3, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[[0, 6, 4, 2], [5, 3, 8, 2], [7, 3, 1, 1]],[[3, 8, 1, 6], [3, 6, 4, 7], [2, 3, 1, 1]],[[1, 0, 2, 0], [1, 7, 2, 2], [9, 5, 9, 4]]], dtype=torch.float32)\n",
    "print(t)\n",
    "print('Dimension is {}, and size is {}'.format(t.dim(), t.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1111,  112],\n",
      "          [ 121,  122],\n",
      "          [ 131,  132]],\n",
      "\n",
      "         [[1211,  112],\n",
      "          [ 221,  122],\n",
      "          [ 231,  132]],\n",
      "\n",
      "         [[1311,  312],\n",
      "          [ 321,  322],\n",
      "          [ 331,  332]],\n",
      "\n",
      "         [[1411,  412],\n",
      "          [ 421,  322],\n",
      "          [ 431,  432]]],\n",
      "\n",
      "\n",
      "        [[[2111,  112],\n",
      "          [ 121,  122],\n",
      "          [ 131,  132]],\n",
      "\n",
      "         [[2211,  112],\n",
      "          [ 221,  122],\n",
      "          [ 231,  132]],\n",
      "\n",
      "         [[2311,  312],\n",
      "          [ 321,  322],\n",
      "          [ 331,  332]],\n",
      "\n",
      "         [[2411,  412],\n",
      "          [ 421,  322],\n",
      "          [ 431,  432]]],\n",
      "\n",
      "\n",
      "        [[[3111,  112],\n",
      "          [ 121,  122],\n",
      "          [ 131,  132]],\n",
      "\n",
      "         [[3211,  112],\n",
      "          [ 221,  122],\n",
      "          [ 231,  132]],\n",
      "\n",
      "         [[3311,  312],\n",
      "          [ 321,  322],\n",
      "          [ 331,  332]],\n",
      "\n",
      "         [[3411,  412],\n",
      "          [ 421,  322],\n",
      "          [ 431,  432]]],\n",
      "\n",
      "\n",
      "        [[[4111,  112],\n",
      "          [ 121,  122],\n",
      "          [ 131,  132]],\n",
      "\n",
      "         [[4211,  112],\n",
      "          [ 221,  122],\n",
      "          [ 231,  132]],\n",
      "\n",
      "         [[4311,  312],\n",
      "          [ 321,  322],\n",
      "          [ 331,  332]],\n",
      "\n",
      "         [[4411,  412],\n",
      "          [ 421,  322],\n",
      "          [ 431,  432]]],\n",
      "\n",
      "\n",
      "        [[[5111,  112],\n",
      "          [ 121,  122],\n",
      "          [ 131,  132]],\n",
      "\n",
      "         [[5211,  112],\n",
      "          [ 221,  122],\n",
      "          [ 231,  132]],\n",
      "\n",
      "         [[5311,  312],\n",
      "          [ 321,  322],\n",
      "          [ 331,  332]],\n",
      "\n",
      "         [[5411,  412],\n",
      "          [ 421,  322],\n",
      "          [ 431,  432]]]], names=('N', 'C', 'H', 'W'))\n",
      "Dimension is 4, and size is torch.Size([5, 4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([[[[1111, 112],[121,122],[131,132]],\n",
    "  [[1211, 112],[221,122],[231,132]], \n",
    "  [[1311, 312],[321,322],[331,332]],\n",
    "  [[1411, 412],[421,322],[431,432]]],\n",
    " [[[2111, 112],[121,122],[131,132]],\n",
    "  [[2211, 112],[221,122],[231,132]], \n",
    "  [[2311, 312],[321,322],[331,332]],\n",
    "  [[2411, 412],[421,322],[431,432]]],\n",
    " [[[3111, 112],[121,122],[131,132]],\n",
    "  [[3211, 112],[221,122],[231,132]], \n",
    "  [[3311, 312],[321,322],[331,332]],\n",
    "  [[3411, 412],[421,322],[431,432]]],\n",
    " [[[4111, 112],[121,122],[131,132]],\n",
    "  [[4211, 112],[221,122],[231,132]], \n",
    "  [[4311, 312],[321,322],[331,332]],\n",
    "  [[4411, 412],[421,322],[431,432]]],\n",
    " [[[5111, 112],[121,122],[131,132]],\n",
    "  [[5211, 112],[221,122],[231,132]], \n",
    "  [[5311, 312],[321,322],[331,332]],\n",
    "  [[5411, 412],[421,322],[431,432]]]], names=[\"N\", \"C\", \"H\", \"W\"])\n",
    "print(t2)\n",
    "print('Dimension is {}, and size is {}'.format(t2.dim(), t2.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor elements types\n",
    "Possbile tensor elements are Boolean (torch.bool) and the followign numeric types:\n",
    "<img src=\"./figures/data_types.PNG\" alt=\"data_types.PNG\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing tensor\n",
    "Zero dimensional tensors cannot be indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(2)\n",
      "2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5488/4116121441.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "print(type(s))\n",
    "print(s)\n",
    "print(int(s))\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(v))\n",
    "print(v)\n",
    "print(int(v[0]))\n",
    "int(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get 1st row and 2nd column of matrix m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = m[0]\n",
    "c2 = m[:,1]\n",
    "print(\"m = \\n {}\".format(m))\n",
    "print(\"r1 = \\n {}\".format(r1))\n",
    "print(\"c2 = \\n {}\".format(c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1[:] = torch.tensor([8, 9, 7, 9])\n",
    "c2[1] = 100\n",
    "print(\"m = \\n {}\".format(m))\n",
    "print(\"r1 = \\n {}\".format(r1))\n",
    "print(\"c2 = \\n {}\".format(c2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign operator \"=\" **returns a reference** (pointing to the same location in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = torch.tensor([1, 0, 2, 0])\n",
    "c2[1] = 7\n",
    "print(\"m = \\n {}\".format(m))\n",
    "print(\"r1 = \\n {}\".format(r1))\n",
    "print(\"c2 = \\n {}\".format(c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[0] = torch.tensor([1, 0, 2, 0])\n",
    "r1[-1] = 100\n",
    "print(\"m = \\n {}\".format(m))\n",
    "print(\"r1 = \\n {}\".format(r1))\n",
    "print(\"c2 = \\n {}\".format(c2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to do if we don't want pointers on existing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = m[0].clone()\n",
    "c2 = m[:,1].clone()\n",
    "print(\"m = \\n {}\".format(m))\n",
    "print(\"r1 = \\n {}\".format(r1))\n",
    "print(\"c2 = \\n {}\".format(c2))\n",
    "r1[:] = torch.tensor([8, 9, 7, 9])\n",
    "c2[1] = 100\n",
    "print(\"\\nAfter the change\")\n",
    "print(\"m = \\n {}\".format(m))\n",
    "print(\"r1 = \\n {}\".format(r1))\n",
    "print(\"c2 = \\n {}\".format(c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t2 = \\n {}\".format(t2))\n",
    "print(\"t2[:,:,:,0] = \\n {}\".format(t2[:,:,:,0]))\n",
    "print(\"t2[:,:,:3:2,0] = \\n {}\".format(t2[:,:,:3:2,0]))\n",
    "print(\"t2[:,:,2,0] = \\n {}\".format(t2[:,:,2,0]))\n",
    "print(\"t2[4,0,:,:] = \\n {}\".format(t2[4,0,:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced indexing\n",
    "\n",
    "Using tensor with Boolean values to index data in tensor.\n",
    "Advance indexing **is not supported in tensors containing names**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = t2.rename(None)\n",
    "target_indices = torch.tensor([False, False, True, True, True])\n",
    "print(type(target_indices))\n",
    "print(t3[target_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_indices2 = torch.tensor([True, True, False, False])\n",
    "print(type(target_indices2))\n",
    "t4 = t3[:, target_indices2]\n",
    "print(\"t4.shape = {}\".format(t4.shape))\n",
    "print(t4)\n",
    "t4[0,0,0,0] = 101\n",
    "print(\"t4 = {}\".format(t4))\n",
    "print(\"t3 = {}\".format(t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = t3[target_indices, target_indices2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_indices = t3 > 0\n",
    "target_indices[0:2,:,:,:] = False\n",
    "target_indices[:,2:4,:,:] = False\n",
    "t4 = t3[target_indices]\n",
    "print(\"t4.shape = {}\".format(t4.shape))\n",
    "print(\"t4 = {}\".format(t4))\n",
    "t4 = t4.view(-1,2,3,2)\n",
    "print(\"\\nafter view()\")\n",
    "print(\"t4.shape = {}\".format(t4.shape))\n",
    "print(\"t4 = {}\".format(t4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t2.float().mean(-3) = {}\".format(t2.float().mean(-3)))\n",
    "print(\"t2.float().mean('C')= {}\".format(t2.float().mean('C')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([0.5, 0.3, 0.2, 0.1])\n",
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze(-1)\n",
    "print(unsqueezed_weights.shape)\n",
    "t2_weights = t2 * unsqueezed_weights\n",
    "t2_weighted_sum = t2.sum(-3)\n",
    "print(t2_weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([0.5, 0.3, 0.2, 0.1], names=['C'])\n",
    "weights_aligned = weights.align_as(t2)\n",
    "t2_weights = t2 * unsqueezed_weights\n",
    "t2_weighted_sum = t2.sum('C')\n",
    "print(t2_weighted_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t2 - t2.float().mean('C').align_as(t2)) / (t2.float().std('C').align_as(t2) + 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The tensor API\n",
    "All tensor operations can be divided into following groups:\n",
    "* Cration operations — functions for constructing a tensor (e.g. ones, zeros ...).\n",
    "* Random sampling — Functions for generating values by drawing randomly from probability distributions (e.g. randn, normal, ...).\n",
    "* Serialization — Functions for saving and loading tensors (e.g load and save).\n",
    "* Indexing, slicing, joining, mutating operations — Functions for changing the shape, stride, or content of a tensor (e.g. transpose, view, ...).\n",
    "* Math operations — \n",
    "    * Elementwise operations — Functions for obtaining a new tensor by applying a function to each element independently (e.g abs, cos, ...).\n",
    "    * Aggregation operations — Functions for computing aggregate values by iterating through tensors (e.g. mean, std, norm).\n",
    "    * Comparison operations — Functions for evaluating numerical predicates over tensors (e.g. equal, max, ...).\n",
    "    * Spectral operations — Functions for transforming in and operating in the frequency domain (e.g. stft, hamming_window, ...).\n",
    "    * BLAS and LAPAC operations — Functions following the Basic Linear Algebra Subprograms (BLAS) and Linear Algebra Package (LAPAC) specification for scalar, vector-vector, matrix-vector, and matrix-matrix operations (e.g. svd, qr, ...).\n",
    "    * Other operations — Functions operating on vectors or matrices (e.g. cross, trace, ...).\n",
    "* Parallelism — Functions for controlling the number of threads for parallel CPU execution (e.g. set_num_threads, ...).\n",
    "\n",
    "More details in http://pytorch.org/docs/stable/torch.html#tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor - storage\n",
    "<img src=\"./figures/tensor_storage.PNG\" alt=\"tensor_storage.PNG\" width=\"550\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t = {}\".format(t))\n",
    "print(\"t.storage() = {}\".format(t.storage()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t.size() = {}\".format(t.size()))\n",
    "t_stride = t.stride()\n",
    "print(\"t.stride() = {}\".format(t_stride))\n",
    "print(\"t.storage_offset() = {}\".format(t.storage_offset()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```t[i,j,k] = t.storage_offset() + i * t.stride[0] + j * t.stride[1] + k * t.stride[2] ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t[1,2,1] = {}\".format(t[1, 2, 1]))\n",
    "print(\"position in storage = {}\".format(t[1, 2, 1].storage_offset()))\n",
    "position = t.storage_offset() + 1 * t_stride[0] + 2 * t_stride[1] + 1 * t_stride[2]\n",
    "print(\"position by formula = {}\".format(position))\n",
    "print(\"t[1,2,1] value in storage = {}\".format(t.storage()[position]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we do transpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = t.transpose(0, 2)\n",
    "print(\"tt.size() = {}\".format(tt.size()))\n",
    "tt_stride = tt.stride()\n",
    "print(\"tt.stride() = {}\".format(tt_stride))\n",
    "print(\"tt.storage_offset() = {}\".format(tt.storage_offset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.storage().data_ptr() == tt.storage().data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = tt.contiguous()\n",
    "print(\"tt.size() = {}\".format(tt.size()))\n",
    "tt_stride = tt.stride()\n",
    "print(\"tt.stride() = {}\".format(tt_stride))\n",
    "print(\"tt.storage_offset() = {}\".format(tt.storage_offset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.storage().data_ptr() == tt.storage().data_ptr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving tensors to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = torch.tensor([[11, 9], [7, 5], [22, 9]], device='cuda', dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(m.float().transpose(0, 1), m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(m.to(device='cuda', dtype=torch.float32).transpose(0, 1), m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(m.to(dtype=torch.float32).transpose(0, 1), m2.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensor and NumPy array\n",
    "\n",
    "Conversion is possible if a tensor is on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_np = m.numpy()\n",
    "print(type(m_np))\n",
    "m2_np = m2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_np = m2.cpu().numpy()\n",
    "print(type(m2_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m3 = torch.from_numpy(m2_np)\n",
    "print(type(m3))\n",
    "print(m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(t, './my_t_a.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./my_t_b.t','wb') as f:\n",
    "   torch.save(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_a = torch.load('./my_t_b.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./my_t_a.t','rb') as f:\n",
    "   tx_b = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"t = {}\".format(t))\n",
    "print(\"tx_a = {}\".format(tx_a))\n",
    "print(\"tx_b = {}\".format(tx_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor interoperability - HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File('./t.hdf5', 'w')\n",
    "dset = f.create_dataset('t_ex', data=t.numpy())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('./t.hdf5', 'r')\n",
    "dset = f['t_ex']\n",
    "t_copy = torch.from_numpy(dset[:])\n",
    "f.close()\n",
    "print(\"t = {}\".format(t))\n",
    "print(\"t_copy = {}\".format(t_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
